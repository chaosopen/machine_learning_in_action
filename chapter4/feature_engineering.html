<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>4.2 特征工程 | 《人工智能之机器学习入门到实战》电子书</title>
    <meta name="generator" content="VuePress 1.9.10">
    <script>var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?ad853f2bf7970012985d6598765c2f9a";
          var s = document.getElementsByTagName("script")[0]; 
          s.parentNode.insertBefore(hm, s);
        })();</script>
    <meta name="description" content="">
    <meta name="keywords" content="人工智能,机器学习,数据分析">
    
    <link rel="preload" href="/assets/css/0.styles.fc446acf.css" as="style"><link rel="preload" href="/assets/js/app.d8974754.js" as="script"><link rel="preload" href="/assets/js/4.c4ff76d6.js" as="script"><link rel="preload" href="/assets/js/1.bfbdf300.js" as="script"><link rel="preload" href="/assets/js/25.09982af2.js" as="script"><link rel="prefetch" href="/assets/js/11.a789a3a6.js"><link rel="prefetch" href="/assets/js/12.2c0cace7.js"><link rel="prefetch" href="/assets/js/13.2b46b2e1.js"><link rel="prefetch" href="/assets/js/14.646dcb04.js"><link rel="prefetch" href="/assets/js/15.e89d864b.js"><link rel="prefetch" href="/assets/js/16.ec274341.js"><link rel="prefetch" href="/assets/js/17.0839d42f.js"><link rel="prefetch" href="/assets/js/18.954c84db.js"><link rel="prefetch" href="/assets/js/19.b518d285.js"><link rel="prefetch" href="/assets/js/2.5a23befa.js"><link rel="prefetch" href="/assets/js/20.53970987.js"><link rel="prefetch" href="/assets/js/21.2338aa9c.js"><link rel="prefetch" href="/assets/js/22.30fc9cde.js"><link rel="prefetch" href="/assets/js/23.978ae11f.js"><link rel="prefetch" href="/assets/js/24.0e445b2e.js"><link rel="prefetch" href="/assets/js/26.a4ef7a52.js"><link rel="prefetch" href="/assets/js/27.f1d4807a.js"><link rel="prefetch" href="/assets/js/28.e371a649.js"><link rel="prefetch" href="/assets/js/29.0fd1dd7b.js"><link rel="prefetch" href="/assets/js/3.75fc72be.js"><link rel="prefetch" href="/assets/js/30.773fd89c.js"><link rel="prefetch" href="/assets/js/31.6076da38.js"><link rel="prefetch" href="/assets/js/32.f825479a.js"><link rel="prefetch" href="/assets/js/33.a29f3ceb.js"><link rel="prefetch" href="/assets/js/34.f2af317e.js"><link rel="prefetch" href="/assets/js/35.511501a7.js"><link rel="prefetch" href="/assets/js/36.8648a2d4.js"><link rel="prefetch" href="/assets/js/37.316eadb4.js"><link rel="prefetch" href="/assets/js/38.499d1579.js"><link rel="prefetch" href="/assets/js/39.7a208fe4.js"><link rel="prefetch" href="/assets/js/40.8d17af82.js"><link rel="prefetch" href="/assets/js/41.6c93ae02.js"><link rel="prefetch" href="/assets/js/42.e4d6db78.js"><link rel="prefetch" href="/assets/js/43.84b121d5.js"><link rel="prefetch" href="/assets/js/44.1aa053e8.js"><link rel="prefetch" href="/assets/js/45.3a4e7f3e.js"><link rel="prefetch" href="/assets/js/46.e4225b3b.js"><link rel="prefetch" href="/assets/js/47.1aa4acbd.js"><link rel="prefetch" href="/assets/js/48.26f8e6df.js"><link rel="prefetch" href="/assets/js/49.eef41bc0.js"><link rel="prefetch" href="/assets/js/5.c1285393.js"><link rel="prefetch" href="/assets/js/50.a05f3f51.js"><link rel="prefetch" href="/assets/js/51.83251fba.js"><link rel="prefetch" href="/assets/js/52.1b3cebd4.js"><link rel="prefetch" href="/assets/js/53.54dd6a71.js"><link rel="prefetch" href="/assets/js/54.651a7cd3.js"><link rel="prefetch" href="/assets/js/55.fb0937d5.js"><link rel="prefetch" href="/assets/js/56.23b34fb2.js"><link rel="prefetch" href="/assets/js/57.58454b35.js"><link rel="prefetch" href="/assets/js/58.d10028ff.js"><link rel="prefetch" href="/assets/js/59.aa56fec1.js"><link rel="prefetch" href="/assets/js/6.c05d10c1.js"><link rel="prefetch" href="/assets/js/7.a9232db4.js"><link rel="prefetch" href="/assets/js/8.7bceb903.js"><link rel="prefetch" href="/assets/js/vendors~docsearch.6a75a8f0.js">
    <link rel="stylesheet" href="/assets/css/0.styles.fc446acf.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">《人工智能之机器学习入门到实战》电子书</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  主页
</a></div><div class="nav-item"><a href="/guide/" class="nav-link">
  一起交流
</a></div><div class="nav-item"><a href="/sponsor.html" class="nav-link">
  赞助
</a></div><div class="nav-item"><a href="https://github.com/chaosopen/machine_learning_in_action" target="_blank" rel="noopener noreferrer" class="nav-link external">
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  主页
</a></div><div class="nav-item"><a href="/guide/" class="nav-link">
  一起交流
</a></div><div class="nav-item"><a href="/sponsor.html" class="nav-link">
  赞助
</a></div><div class="nav-item"><a href="https://github.com/chaosopen/machine_learning_in_action" target="_blank" rel="noopener noreferrer" class="nav-link external">
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav>  <ul class="sidebar-links"><li><a href="/" aria-current="page" class="sidebar-link">首页</a></li><li><section class="sidebar-group depth-0"><a href="/chapter1/index" class="sidebar-heading clickable"><span>第一章：人工智能入门</span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/chapter1/ai_intro.html" class="sidebar-link">1.1 人工智能介绍</a></li><li><a href="/chapter1/ml_intro.html" class="sidebar-link">1.2 机器学习介绍</a></li></ul></section></li><li><section class="sidebar-group depth-0"><a href="/chapter2/index" class="sidebar-heading clickable"><span>第二章：机器学习基础</span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/chapter2/ml_workflow.html" class="sidebar-link">2.1 机器学习工作流程</a></li><li><a href="/chapter2/ml_category.html" class="sidebar-link">2.2 机器学习算法分类</a></li><li><a href="/chapter2/model_intro.html" class="sidebar-link">2.3 模型介绍</a></li><li><a href="/chapter2/install_ml.html" class="sidebar-link">2.4 安装机器学习环境</a></li><li><a href="/chapter2/first_ml_project.html" class="sidebar-link">2.5 第一个机器学习项目</a></li></ul></section></li><li><section class="sidebar-group depth-0"><a href="/chapter3/index" class="sidebar-heading clickable"><span>第三章：机器学习算法</span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/chapter3/knn.html" class="sidebar-link">3.1 K-近邻算法介绍</a></li><li><a href="/chapter3/decision_tree.html" class="sidebar-link">3.2 决策树算法</a></li><li><a href="/chapter3/naive_bayes.html" class="sidebar-link">3.3 朴素贝叶斯算法</a></li><li><a href="/chapter3/linear_regression.html" class="sidebar-link">3.4 线性回归算法</a></li><li><a href="/chapter3/logistic_regression.html" class="sidebar-link">3.5 逻辑回归算法</a></li><li><a href="/chapter3/svm.html" class="sidebar-link">3.6 SVM算法</a></li><li><a href="/chapter3/random_forest.html" class="sidebar-link">3.7 随机森林算法</a></li><li><a href="/chapter3/kmeans.html" class="sidebar-link">3.8 K-Means聚类算法</a></li><li><a href="/chapter3/algorithm_selection.html" class="sidebar-link">3.9 算法选择建议</a></li></ul></section></li><li><section class="sidebar-group depth-0"><a href="/chapter4/index" class="sidebar-heading clickable open"><span>第四章：算法通用知识</span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/chapter4/distance_measurement.html" class="sidebar-link">4.1 距离度量</a></li><li><a href="/chapter4/feature_engineering.html" aria-current="page" class="active sidebar-link">4.2 特征工程</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/chapter4/feature_engineering.html#_4-2-1-特征提取" class="sidebar-link">4.2.1 特征提取</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/chapter4/feature_engineering.html#_1-特征提取介绍" class="sidebar-link">1. 特征提取介绍</a></li><li class="sidebar-sub-header"><a href="/chapter4/feature_engineering.html#_2-字典特征提取" class="sidebar-link">2. 字典特征提取</a></li><li class="sidebar-sub-header"><a href="/chapter4/feature_engineering.html#_3-文本特征提取" class="sidebar-link">3. 文本特征提取</a></li><li class="sidebar-sub-header"><a href="/chapter4/feature_engineering.html#_4-jieba分词文本特征提取" class="sidebar-link">4. jieba分词文本特征提取</a></li><li class="sidebar-sub-header"><a href="/chapter4/feature_engineering.html#_5-tf-idf文本特征提取" class="sidebar-link">5. Tf-idf文本特征提取</a></li></ul></li></ul></li><li><a href="/chapter4/regression_evaluation.html" class="sidebar-link">4.3 回归问题评估</a></li></ul></section></li><li><section class="sidebar-group depth-0"><a href="/chapter5/index" class="sidebar-heading clickable"><span>第五章：机器学习实战</span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/chapter5/spam_classify.html" class="sidebar-link">5.1 垃圾邮箱分类项目</a></li><li><a href="/chapter5/boston_house_price_forecast.html" class="sidebar-link">5.2 波士顿房价预测项目</a></li><li><a href="/chapter5/stock_price_predict.html" class="sidebar-link">5.3 股价预测项目</a></li><li><a href="/chapter5/card_anti_fraud.html" class="sidebar-link">5.4 信用卡反欺诈项目信用</a></li><li><a href="/chapter5/movie_recommend.html" class="sidebar-link">5.5 电影推荐系统</a></li></ul></section></li><li><a href="/sponsor.html" class="sidebar-link">赞助</a></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="_4-2-特征工程"><a href="#_4-2-特征工程" class="header-anchor">#</a> 4.2 特征工程</h1> <h2 id="_4-2-1-特征提取"><a href="#_4-2-1-特征提取" class="header-anchor">#</a> 4.2.1 特征提取</h2> <h3 id="_1-特征提取介绍"><a href="#_1-特征提取介绍" class="header-anchor">#</a> 1. 特征提取介绍</h3> <p>将任意数据（如文本或图像）转换为可用于机器学习的数字特征</p> <blockquote><p>特征值化是为了计算机更好的去理解数据</p></blockquote> <ul><li>特征提取分类:
<ul><li>字典特征提取(特征离散化)</li> <li>文本特征提取</li> <li>图像特征提取（深度学习介绍）</li></ul></li></ul> <p>在本书示例Sklearn包中，特征提取的API如下：</p> <div class="language-py extra-class"><pre class="language-py"><code>sklearn<span class="token punctuation">.</span>feature_extraction
</code></pre></div><h3 id="_2-字典特征提取"><a href="#_2-字典特征提取" class="header-anchor">#</a> 2. 字典特征提取</h3> <p>对以下数据进行特征抽取</p> <div class="language- extra-class"><pre class="language-text"><code>[{'city': '北京','temperature':100},
{'city': '上海','temperature':60},
{'city': '深圳','temperature':30}]
</code></pre></div><p>代码示例：</p> <div class="language-py extra-class"><pre class="language-py"><code><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction <span class="token keyword">import</span> DictVectorizer

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'北京'</span><span class="token punctuation">,</span><span class="token string">'temperature'</span><span class="token punctuation">:</span><span class="token number">100</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'上海'</span><span class="token punctuation">,</span><span class="token string">'temperature'</span><span class="token punctuation">:</span><span class="token number">60</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'深圳'</span><span class="token punctuation">,</span><span class="token string">'temperature'</span><span class="token punctuation">:</span><span class="token number">30</span><span class="token punctuation">}</span><span class="token punctuation">]</span>
    <span class="token comment"># 1、实例化一个转换器类</span>
    transfer <span class="token operator">=</span> DictVectorizer<span class="token punctuation">(</span>sparse<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token comment"># 2、调用fit_transform</span>
    data <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;返回的结果:\n&quot;</span><span class="token punctuation">,</span> data<span class="token punctuation">)</span>
    <span class="token comment"># 打印特征名字</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;特征名字：\n&quot;</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>输出结果为：</p> <div class="language-py extra-class"><pre class="language-py"><code>返回的结果<span class="token punctuation">:</span>
 <span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">0.</span>   <span class="token number">1.</span>   <span class="token number">0.</span> <span class="token number">100.</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">1.</span>   <span class="token number">0.</span>   <span class="token number">0.</span>  <span class="token number">60.</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">0.</span>   <span class="token number">0.</span>   <span class="token number">1.</span>  <span class="token number">30.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
特征名字：
 <span class="token punctuation">[</span><span class="token string">'city=上海'</span><span class="token punctuation">,</span> <span class="token string">'city=北京'</span><span class="token punctuation">,</span> <span class="token string">'city=深圳'</span><span class="token punctuation">,</span> <span class="token string">'temperature'</span><span class="token punctuation">]</span>
</code></pre></div><p>我们把这个处理数据的技巧叫做”one-hot“编码：
<img src="/assets/img/4-2-1.db9a3ab6.png" alt="图4-2-1"></p> <p>转化为：</p> <p><img src="/assets/img/4-2-2.07d213c9.png" alt="图4-2-2"></p> <p>对于特征当中存在类别信息的我们都会做one-hot编码处理</p> <h3 id="_3-文本特征提取"><a href="#_3-文本特征提取" class="header-anchor">#</a> 3. 文本特征提取</h3> <p>对以下数据进行特征抽取</p> <div class="language- extra-class"><pre class="language-text"><code>[&quot;life is short,i like python&quot;,
&quot;life is too long,i dislike python&quot;]
</code></pre></div><p>代码示例：</p> <div class="language-py extra-class"><pre class="language-py"><code><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;life is short,i like python&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;life is too long,i dislike python&quot;</span><span class="token punctuation">]</span>
    <span class="token comment"># 1、实例化一个转换器类</span>
    transfer <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 2、调用fit_transform</span>
    data <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;文本特征抽取的结果：\n&quot;</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;返回特征名字：\n&quot;</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>输出结果为：</p> <div class="language-py extra-class"><pre class="language-py"><code>文本特征抽取的结果：
 <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
返回特征名字：
 <span class="token punctuation">[</span><span class="token string">'dislike'</span><span class="token punctuation">,</span> <span class="token string">'is'</span><span class="token punctuation">,</span> <span class="token string">'life'</span><span class="token punctuation">,</span> <span class="token string">'like'</span><span class="token punctuation">,</span> <span class="token string">'long'</span><span class="token punctuation">,</span> <span class="token string">'python'</span><span class="token punctuation">,</span> <span class="token string">'short'</span><span class="token punctuation">,</span> <span class="token string">'too'</span><span class="token punctuation">]</span>
</code></pre></div><p><strong>数据需要用空格分开，英文默认空格分开的，达到了分词的效果，中文需要借助分词器</strong></p> <h3 id="_4-jieba分词文本特征提取"><a href="#_4-jieba分词文本特征提取" class="header-anchor">#</a> 4. jieba分词文本特征提取</h3> <p>需要安装jieba库</p> <div class="language-shell extra-class"><pre class="language-shell"><code>pip3 <span class="token function">install</span> jieba
</code></pre></div><p>示例代码：</p> <div class="language-py extra-class"><pre class="language-py"><code><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer
<span class="token keyword">import</span> jieba

<span class="token keyword">def</span> <span class="token function">cut_word</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 用结巴对中文字符串进行分词</span>
    text <span class="token operator">=</span> <span class="token string">&quot; &quot;</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> text

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。&quot;</span><span class="token punctuation">,</span>
            <span class="token string">&quot;我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。&quot;</span><span class="token punctuation">,</span>
            <span class="token string">&quot;如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。&quot;</span><span class="token punctuation">]</span>
    <span class="token comment"># 将原始数据转换成分好词的形式</span>
    text_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> sent <span class="token keyword">in</span> data<span class="token punctuation">:</span>
        text_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cut_word<span class="token punctuation">(</span>sent<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>text_list<span class="token punctuation">)</span>

    <span class="token comment"># 1、实例化一个转换器类</span>
    transfer <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 2、调用fit_transform</span>
    data <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>text_list<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;文本特征抽取的结果：\n&quot;</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;返回特征名字：\n&quot;</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>运行结果：</p> <div class="language-py extra-class"><pre class="language-py"><code><span class="token punctuation">[</span><span class="token string">'一种 还是 一种 今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 ， 所以 每个 人 不要 放弃 今天 。'</span><span class="token punctuation">,</span> <span class="token string">'我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。'</span><span class="token punctuation">,</span> <span class="token string">'如果 只用 一种 方式 了解 某样 事物 ， 你 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。'</span><span class="token punctuation">]</span>
文本特征抽取的结果：
 <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">2</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">2</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">2</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span>
  <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">3</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">2</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span>
  <span class="token number">1</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">4</span> <span class="token number">3</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">2</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span>
  <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
返回特征名字：
 <span class="token punctuation">[</span><span class="token string">'一种'</span><span class="token punctuation">,</span> <span class="token string">'不会'</span><span class="token punctuation">,</span> <span class="token string">'不要'</span><span class="token punctuation">,</span> <span class="token string">'之前'</span><span class="token punctuation">,</span> <span class="token string">'了解'</span><span class="token punctuation">,</span> <span class="token string">'事物'</span><span class="token punctuation">,</span> <span class="token string">'今天'</span><span class="token punctuation">,</span> <span class="token string">'光是在'</span><span class="token punctuation">,</span> <span class="token string">'几百万年'</span><span class="token punctuation">,</span> <span class="token string">'发出'</span><span class="token punctuation">,</span> <span class="token string">'取决于'</span><span class="token punctuation">,</span> <span class="token string">'只用'</span><span class="token punctuation">,</span> <span class="token string">'后天'</span><span class="token punctuation">,</span> <span class="token string">'含义'</span><span class="token punctuation">,</span> <span class="token string">'大部分'</span><span class="token punctuation">,</span> <span class="token string">'如何'</span><span class="token punctuation">,</span> <span class="token string">'如果'</span><span class="token punctuation">,</span> <span class="token string">'宇宙'</span><span class="token punctuation">,</span> <span class="token string">'我们'</span><span class="token punctuation">,</span> <span class="token string">'所以'</span><span class="token punctuation">,</span> <span class="token string">'放弃'</span><span class="token punctuation">,</span> <span class="token string">'方式'</span><span class="token punctuation">,</span> <span class="token string">'明天'</span><span class="token punctuation">,</span> <span class="token string">'星系'</span><span class="token punctuation">,</span> <span class="token string">'晚上'</span><span class="token punctuation">,</span> <span class="token string">'某样'</span><span class="token punctuation">,</span> <span class="token string">'残酷'</span><span class="token punctuation">,</span> <span class="token string">'每个'</span><span class="token punctuation">,</span> <span class="token string">'看到'</span><span class="token punctuation">,</span> <span class="token string">'真正'</span><span class="token punctuation">,</span> <span class="token string">'秘密'</span><span class="token punctuation">,</span> <span class="token string">'绝对'</span><span class="token punctuation">,</span> <span class="token string">'美好'</span><span class="token punctuation">,</span> <span class="token string">'联系'</span><span class="token punctuation">,</span> <span class="token string">'过去'</span><span class="token punctuation">,</span> <span class="token string">'还是'</span><span class="token punctuation">,</span> <span class="token string">'这样'</span><span class="token punctuation">]</span>
</code></pre></div><p>jieba把句子分成多个词，然后做文本特征抽取</p> <h3 id="_5-tf-idf文本特征提取"><a href="#_5-tf-idf文本特征提取" class="header-anchor">#</a> 5. Tf-idf文本特征提取</h3> <ul><li>TF-IDF的主要思想是：如果某个词或短语在一篇文章中出现的概率高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。</li> <li>TF-IDF作用：用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。</li></ul> <h4 id="_1-公式"><a href="#_1-公式" class="header-anchor">#</a> 1. 公式</h4> <ul><li>词频（term frequency，tf）指的是某一个给定的词语在该文件中出现的频率</li> <li>逆向文档频率（inverse document frequency，idf）是一个词语普遍重要性的度量。某一特定词语的idf，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取以10为底的对数得到</li></ul> <p><img src="data:image/png;base64,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" alt="图4-2-3"></p> <p>最终得出结果可以理解为重要程度。</p> <p>举例：</p> <p>假如一篇文章的总词语数是100个，而词语&quot;非常&quot;出现了5次，那么&quot;非常&quot;一词在该文件中的词频就是5/100=0.05。<br>
而计算文件频率（IDF）的方法是以文件集的文件总数，除以出现&quot;非常&quot;一词的文件数。<br>
所以，如果&quot;非常&quot;一词在1,0000份文件出现过，而文件总数是10,000,000份的话，<br>
其逆向文件频率就是lg（10,000,000 / 1,0000）=3。<br>
最后&quot;非常&quot;对于这篇文档的tf-idf的分数为0.05 * 3=0.15</p> <h4 id="_2-代码示例"><a href="#_2-代码示例" class="header-anchor">#</a> 2. 代码示例</h4> <div class="language-py extra-class"><pre class="language-py"><code><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> TfidfVectorizer
<span class="token keyword">import</span> jieba
<span class="token keyword">def</span> <span class="token function">cut_word</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 用结巴对中文字符串进行分词</span>
    text <span class="token operator">=</span> <span class="token string">&quot; &quot;</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> text

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。&quot;</span><span class="token punctuation">,</span>
            <span class="token string">&quot;我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。&quot;</span><span class="token punctuation">,</span>
            <span class="token string">&quot;如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。&quot;</span><span class="token punctuation">]</span>
    <span class="token comment"># 将原始数据转换成分好词的形式</span>
    text_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> sent <span class="token keyword">in</span> data<span class="token punctuation">:</span>
        text_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cut_word<span class="token punctuation">(</span>sent<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>text_list<span class="token punctuation">)</span>

    <span class="token comment"># 1、实例化一个转换器类</span>
    transfer <span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span>stop_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'一种'</span><span class="token punctuation">,</span> <span class="token string">'不会'</span><span class="token punctuation">,</span> <span class="token string">'不要'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># 2、调用fit_transform</span>
    data <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>text_list<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;文本特征抽取的结果：\n&quot;</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;返回特征名字：\n&quot;</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>返回结果：</p> <div class="language-py extra-class"><pre class="language-py"><code><span class="token punctuation">[</span><span class="token string">'一种 还是 一种 今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 ， 所以 每个 人 不要 放弃 今天 。'</span><span class="token punctuation">,</span> <span class="token string">'我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。'</span><span class="token punctuation">,</span> <span class="token string">'如果 只用 一种 方式 了解 某样 事物 ， 你 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。'</span><span class="token punctuation">]</span>
文本特征抽取的结果：
 <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.43643578</span> <span class="token number">0.</span>         <span class="token number">0.</span>
  <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.21821789</span> <span class="token number">0.</span>         <span class="token number">0.21821789</span>
  <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.21821789</span> <span class="token number">0.21821789</span>
  <span class="token number">0.</span>         <span class="token number">0.43643578</span> <span class="token number">0.</span>         <span class="token number">0.21821789</span> <span class="token number">0.</span>         <span class="token number">0.43643578</span>
  <span class="token number">0.21821789</span> <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.21821789</span> <span class="token number">0.21821789</span>
  <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.21821789</span> <span class="token number">0.</span>        <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.2410822</span>  <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.2410822</span>  <span class="token number">0.2410822</span>
  <span class="token number">0.2410822</span>  <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>
  <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.2410822</span>  <span class="token number">0.55004769</span> <span class="token number">0.</span>         <span class="token number">0.</span>
  <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.2410822</span>  <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>
  <span class="token number">0.</span>         <span class="token number">0.48216441</span> <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>
  <span class="token number">0.</span>         <span class="token number">0.2410822</span>  <span class="token number">0.</span>         <span class="token number">0.2410822</span> <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.</span>         <span class="token number">0.644003</span>   <span class="token number">0.48300225</span> <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>
  <span class="token number">0.</span>         <span class="token number">0.16100075</span> <span class="token number">0.16100075</span> <span class="token number">0.</span>         <span class="token number">0.16100075</span> <span class="token number">0.</span>
  <span class="token number">0.16100075</span> <span class="token number">0.16100075</span> <span class="token number">0.</span>         <span class="token number">0.12244522</span> <span class="token number">0.</span>         <span class="token number">0.</span>
  <span class="token number">0.16100075</span> <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.16100075</span> <span class="token number">0.</span>
  <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.3220015</span>  <span class="token number">0.16100075</span> <span class="token number">0.</span>         <span class="token number">0.</span>
  <span class="token number">0.16100075</span> <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>        <span class="token punctuation">]</span><span class="token punctuation">]</span>
返回特征名字：
 <span class="token punctuation">[</span><span class="token string">'之前'</span><span class="token punctuation">,</span> <span class="token string">'了解'</span><span class="token punctuation">,</span> <span class="token string">'事物'</span><span class="token punctuation">,</span> <span class="token string">'今天'</span><span class="token punctuation">,</span> <span class="token string">'光是在'</span><span class="token punctuation">,</span> <span class="token string">'几百万年'</span><span class="token punctuation">,</span> <span class="token string">'发出'</span><span class="token punctuation">,</span> <span class="token string">'取决于'</span><span class="token punctuation">,</span> <span class="token string">'只用'</span><span class="token punctuation">,</span> <span class="token string">'后天'</span><span class="token punctuation">,</span> <span class="token string">'含义'</span><span class="token punctuation">,</span> <span class="token string">'大部分'</span><span class="token punctuation">,</span> <span class="token string">'如何'</span><span class="token punctuation">,</span> <span class="token string">'如果'</span><span class="token punctuation">,</span> <span class="token string">'宇宙'</span><span class="token punctuation">,</span> <span class="token string">'我们'</span><span class="token punctuation">,</span> <span class="token string">'所以'</span><span class="token punctuation">,</span> <span class="token string">'放弃'</span><span class="token punctuation">,</span> <span class="token string">'方式'</span><span class="token punctuation">,</span> <span class="token string">'明天'</span><span class="token punctuation">,</span> <span class="token string">'星系'</span><span class="token punctuation">,</span> <span class="token string">'晚上'</span><span class="token punctuation">,</span> <span class="token string">'某样'</span><span class="token punctuation">,</span> <span class="token string">'残酷'</span><span class="token punctuation">,</span> <span class="token string">'每个'</span><span class="token punctuation">,</span> <span class="token string">'看到'</span><span class="token punctuation">,</span> <span class="token string">'真正'</span><span class="token punctuation">,</span> <span class="token string">'秘密'</span><span class="token punctuation">,</span> <span class="token string">'绝对'</span><span class="token punctuation">,</span> <span class="token string">'美好'</span><span class="token punctuation">,</span> <span class="token string">'联系'</span><span class="token punctuation">,</span> <span class="token string">'过去'</span><span class="token punctuation">,</span> <span class="token string">'还是'</span><span class="token punctuation">,</span> <span class="token string">'这样'</span><span class="token punctuation">]</span>
</code></pre></div><p>TF-IDF是作为分类机器学习算法进行文章分类中前期数据处理方式</p></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">Last Updated:</span> <span class="time">11/21/2023, 10:51:53 PM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/chapter4/distance_measurement.html" class="prev">
        4.1 距离度量
      </a></span> <span class="next"><a href="/chapter4/regression_evaluation.html">
        4.3 回归问题评估
      </a>
      →
    </span></p></div> <div style="text-align:center;"></div> <div class="copyright"><a target="_blank" href="https://beian.miit.gov.cn">豫ICP备2023030173号-1</a></div> <div class="copyright"> 
        版权所有，禁止私自克隆网站。
      </div></main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.d8974754.js" defer></script><script src="/assets/js/4.c4ff76d6.js" defer></script><script src="/assets/js/1.bfbdf300.js" defer></script><script src="/assets/js/25.09982af2.js" defer></script>
  </body>
</html>
